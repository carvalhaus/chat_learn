version: '3.9'

services:
  nginx:
    image: nginx:alpine
    container_name: chatbot-nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - backend
      - frontend
    restart: unless-stopped

  backend:
    build: ./backend
    container_name: chatbot-backend
    restart: unless-stopped
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
      ollama:
        condition: service_healthy

  frontend:
    build: ./frontend
    container_name: chatbot-frontend
    restart: unless-stopped
    volumes:
      - ./frontend:/app
    ports:
    - "3001:5173"
    depends_on:
      - backend

  db:
    image: mysql:8.0
    container_name: chatbot-db
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: chatbot
      MYSQL_USER: user
      MYSQL_PASSWORD: password
    ports:
      - "3307:3306"
    volumes:
      - db_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin" ,"ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 30

  redis:
    image: redis/redis-stack-server:latest
    container_name: chatbot-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
      - "8001:8001"
    environment:
      - REDIS_ARGS=--requirepass password
  
  ollama:
    build: ./ollama
    container_name: chatbot-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    entrypoint: [ "/usr/bin/bash", "pull-ollama.sh" ]
    healthcheck:
    ##PRECISA AJUSTAR
      test: ["CMD", "curl", "-s", "http://localhost:11434/api/tags | grep llama3.2"]
      interval: 10s
      timeout: 5s
      retries: 10

volumes:
  db_data:
  ollama_data:
